# Forward mode Autodiff and Dual Numbers

### Forward autodiff?

While we're familiar with backward mode autodiff due to the almightly backprop, its not the only
way to auto differentiate.

Before autodiff, we also have to consider the standard differentation procedures.

1. Symbolic Differentiation  
Too computationally intensive to obtain a closed form simplified expression.

2. Finite difference method  
The popular $\frac{d}{dx}f(x) = \lim_{x \to 0}\frac{f(x + h) - f(x)}{h}$.
Suffers from numerical instability.

Both are slow for partial derivative computation with respect to many inputs. A more efficient and
stable method for the same is to multiply a chain of jacobians through simple chain rule.

If $x$ and $y$ are vectors, and -  
$y = h(g(f(x)))$

Then through chain rule,  
$\frac{\partial y}{\partial x} = \frac{\partial h(w_2)}{\partial w_2} \frac{\partial g(w_1)}{\partial w_1} \frac{\partial f(w_0)}{\partial x}$

Where $w_0 = x, w_1 = f(w_0), w_2 = g(w_1)$.

