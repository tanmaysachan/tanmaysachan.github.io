# How did transformers get this good?

Back in 2018 when "Attention is all you need" [paper](https://arxiv.org/abs/1706.03762) was published no one had expected
this architecture to take the NLP world by storm. And then it did. And not just NLP, but computer vision, speech processing,
program synthesis and many more.

Fast forward to 2023, and ChatGPT has revolutionized work flows of people, with openAI's next iteration - GPT-4 - being rumored to take away many jobs owing
to its high level reasoning capabilities and task automation potential.

### But what do transformers do exactly?

Transformers essentially boil down to probability distribution prediction functions. Essentially for some given list of tokens $T = \[t_1, t_2, .. t_n\]$ a transformer gives us the probability distribution for what
$t_{n+1}$ is.

However,